task_name: ${task.name}
experiment: ''
env_path: ''
num_envs: ''
seed: 42
torch_deterministic: false
max_iterations: 3000
physics_engine: physx
pipeline: gpu
sim_device: cuda:0
rl_device: cuda:0
graphics_device_id: 0
num_threads: 4
solver_type: 1
num_subscenes: 4
test: false
checkpoint: ''
sigma: ''
multi_gpu: false
wandb_activate: false
wandb_group: ''
wandb_name: ${train.params.config.name}
wandb_entity: ''
wandb_project: ''
wandb_tags: []
wandb_logcode_dir: ''
capture_video: false
capture_video_freq: 5000
capture_video_len: 200
force_render: false
headless: true
task:
  env:
    actionPenaltyScale: 0.01
    actionScale: 7.5
    aggregateMode: 3
    aroundHandleRewardScale: 0.25
    asset:
      assetFileNameCabinet: urdf/sektion_cabinet_model/urdf/sektion_cabinet_2.urdf
      assetFileNameFranka: urdf/franka_description/robots/franka_panda.urdf
      assetRoot: ../../assets
    clipActions: 1.0
    clipObservations: 5.0
    distRewardScale: 2.0
    dofVelocityScale: 0.1
    enableCameraSensors: false
    enableDebugVis: false
    envSpacing: 1.5
    env_name: franka_cabinetGPT
    episodeLength: 500
    fingerDistRewardScale: 5.0
    numEnvs: ${resolve_default:4096,${...num_envs}}
    numProps: 16
    openRewardScale: 7.5
    rotRewardScale: 0.5
    startPositionNoise: 0.0
    startRotationNoise: 0.0
  name: FrankaCabinetGPT
  physics_engine: ${..physics_engine}
  sim:
    dt: 0.0166
    gravity:
    - 0.0
    - 0.0
    - -9.81
    physx:
      bounce_threshold_velocity: 0.2
      contact_collection: 0
      contact_offset: 0.005
      default_buffer_size_multiplier: 5.0
      max_depenetration_velocity: 1000.0
      max_gpu_contact_pairs: 1048576
      num_position_iterations: 12
      num_subscenes: ${....num_subscenes}
      num_threads: ${....num_threads}
      num_velocity_iterations: 1
      rest_offset: 0.0
      solver_type: ${....solver_type}
      use_gpu: ${contains:"cuda",${....sim_device}}
    substeps: 1
    up_axis: z
    use_gpu_pipeline: ${eq:${...pipeline},"gpu"}
  task:
    randomize: false
train:
  params:
    algo:
      name: a2c_continuous
    config:
      bounds_loss_coef: 0.0001
      clip_value: true
      critic_coef: 4
      e_clip: 0.2
      entropy_coef: 0.0
      env_name: rlgpu
      full_experiment_name: ${.name}
      gamma: 0.99
      grad_norm: 1.0
      horizon_length: 16
      kl_threshold: 0.008
      learning_rate: 0.0005
      lr_schedule: adaptive
      max_epochs: ${resolve_default:1500,${....max_iterations}}
      mini_epochs: 8
      minibatch_size: 8192
      mixed_precision: false
      multi_gpu: false
      name: ${resolve_default:FrankaCabinetGPT,${....experiment}}
      normalize_advantage: true
      normalize_input: true
      normalize_value: true
      num_actors: ${....task.env.numEnvs}
      ppo: true
      print_stats: true
      reward_shaper:
        scale_value: 0.01
      save_best_after: 200
      save_frequency: 100
      score_to_win: 10000
      seq_len: 4
      tau: 0.95
      truncate_grads: true
    load_checkpoint: ${if:${...checkpoint},True,False}
    load_path: ${...checkpoint}
    model:
      name: continuous_a2c_logstd
    network:
      mlp:
        activation: elu
        d2rl: false
        initializer:
          name: default
        regularizer:
          name: None
        units:
        - 256
        - 128
        - 64
      name: actor_critic
      separate: false
      space:
        continuous:
          fixed_sigma: true
          mu_activation: None
          mu_init:
            name: default
          sigma_activation: None
          sigma_init:
            name: const_initializer
            val: 0
    seed: ${...seed}
